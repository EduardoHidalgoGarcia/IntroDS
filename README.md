## Introduction to Data Science


### Summary

In this workshop series named A crash course in Python for Data Science, we will be working with data.

The data that will be using was extracted from [The World Bank](https://databank.worldbank.org/source/world-development-indicators). The extraction period is from 2000 to the last available date (in most cases 2020). 


## Agenda

#### Part 1

| General Topic | Single topics  | Type | Library  |
| :-----: | :-: | :-: | :-: |
| Datasets | Creating, Reading and Writing | T&E | Pandas |
| Datasets | Indexing, Selecting and Assigning | T&E | Pandas |
| Datasets | Summary Functions and Maps | T&E | Pandas |
| Datasets | Grouping and Sorting | T&E | Pandas |
| Datasets | Data Types and Missing Values | T&E | Pandas |
| Datasets | Renaming and Combining | T&E | Pandas |

#### Part 2

| General Topic | Single topics  | Type | Library  |
| :-----: | :-: | :-: | :-: |
| Datasets | Recap | T&E | Pandas |
| Visualization | Plots from DataFrames | T&E | Matplotlib |


#### Part 3

| General Topic | Single topics  | Type | Library  |
| :-----: | :-: | :-: | :-: |
| Intro to ML | Missing Values | T&E | Scikit-learn |
| Intro to ML | Categorical Variables | T&E | Scikit-learn |
| Intro to ML | Logistic Regression | T&E | Scikit-learn |




#### Part 4

| General Topic | Single topics  | Type | Library  |
| :-----: | :-: | :-: | :-: |
| Machine Learning | Base. mod., Perf. metr. & Cr. Val. | Theory | N/A |
| Machine Learning | Random Forest | T&E | Scikit-learn |
| Machine Learning | Underfitting and Overfitting | T&E | Scikit-learn |




### About the information sources

Below are the links that you can follow to go to the webpages of the courses that serve as basis for the construction of this course. They are arrange by topic:

+ Python: [Udemy](https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB)
+ pandas: [Kaggle Course](https://www.kaggle.com/learn/pandas)
+ Intro to ML: [Kaggle Course](https://www.kaggle.com/learn/intro-to-machine-learning)
+ Machine Learning: [Kaggle Course](https://www.kaggle.com/learn/intermediate-machine-learning)
+ plotnine: [Medium](https://towardsdatascience.com/how-to-use-ggplot2-in-python-74ab8adec129)
+ Github: [Youtube](https://www.youtube.com/results?search_query=what+is+github)
+ Logistic regresion: [DataCamp](https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python)
+ Logistic regresion: [ITAM](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxpdGFtbWFjcm9lY29ub21ldHJpYXxneDpiMjY5ZGZlZWYyM2M2MDE)
+ Performance Metrics: [blog.exsilio.com](https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/)
+ ROC curve: [Wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)
+ XGBoost: [Hackernoon](https://hackernoon.com/want-a-complete-guide-for-xgboost-model-in-python-using-scikit-learn-sc11f31bq)
+ ANN: [Medium](https://medium.com/@sanchittanwar75/introduction-to-neural-networks-660f6909fba9)

